{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "\n",
    "A Convolutional Neural Network was developed to predict if images (current and future) were from two types of classes (Cat or Dog). This predictive model used ten thousand images from the two respective categories for training and testing.\n",
    "\n",
    "## Model Performance\n",
    "\n",
    "The accuracy in the model for the training set was calculated at 96.4% and 87.2% for the testing set. A prediction test was also performed with images independent from both sets. The model correctly determined 12 of 13 images. That is a 92.3% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Keras libraries and packages. \n",
    "#Keras will be using TesorFlow as a backend.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the CNN\n",
    "classifier=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional Layer is being developed\n",
    "#Specifying conditions for Feature Detectors to create Feature Maps \n",
    "classifier.add(Convolution2D(filters=32,kernel_size=(3,3),input_shape=(64,64,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pooling Layer is being developed\n",
    "#This layer will reduce the size of the feature map by converting it in a pooled feature map\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional Layer is being developed from the Pooling Layer\n",
    "#Specifying conditions for Feature Detectors to create Feature Maps \n",
    "classifier.add(Convolution2D(filters=32,kernel_size=(3,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pooling Layer is being developed\n",
    "#This layer will reduce the size of the feature map by converting it in a pooled feature map\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional Layer is being developed from the Pooling Layer\n",
    "#Specifying conditions for Feature Detectors to create Feature Maps \n",
    "classifier.add(Convolution2D(filters=32,kernel_size=(3,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pooling Layer is being developed\n",
    "#This layer will reduce the size of the feature map by converting it in a pooled feature map\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional Layer is being developed from the Pooling Layer\n",
    "#Specifying conditions for Feature Detectors to create Feature Maps \n",
    "classifier.add(Convolution2D(filters=32,kernel_size=(3,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pooling Layer is being developed\n",
    "#This layer will reduce the size of the feature map by converting it in a pooled feature map\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattening is being developed\n",
    "#This task will take the pooled feature maps and puts them in one single vector. \n",
    "#This single vector will become the Input Layer in the ANN\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Artificial Neural Network portion of the model\n",
    "#The Hidden and Output Layers are being developed\n",
    "classifier.add(Dense(units=128,activation='relu'))\n",
    "classifier.add(Dense(units=128,activation='relu'))\n",
    "classifier.add(Dense(units=128,activation='relu'))\n",
    "classifier.add(Dense(units=128,activation='relu'))\n",
    "classifier.add(Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the CNN\n",
    "#The descent and loss conditions will be added. \n",
    "#In this case it will be Stochastic Gradient descent and Logarithmic Loss.\n",
    "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image augmentation to prevent overfitting\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#These sets will create the training set and test set\n",
    "train_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                target_size=(64, 64),\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 2500s 312ms/step - loss: 0.4336 - acc: 0.7865 - val_loss: 0.3648 - val_acc: 0.8390\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 1748s 219ms/step - loss: 0.2740 - acc: 0.8806 - val_loss: 0.3301 - val_acc: 0.8609\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 1729s 216ms/step - loss: 0.2169 - acc: 0.9083 - val_loss: 0.3826 - val_acc: 0.8711\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 1742s 218ms/step - loss: 0.1808 - acc: 0.9250 - val_loss: 0.3699 - val_acc: 0.8727\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 1739s 217ms/step - loss: 0.1550 - acc: 0.9368 - val_loss: 0.3546 - val_acc: 0.8740\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 1733s 217ms/step - loss: 0.1349 - acc: 0.9455 - val_loss: 0.3727 - val_acc: 0.8845\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 1731s 216ms/step - loss: 0.1193 - acc: 0.9524 - val_loss: 0.4167 - val_acc: 0.8686\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 1749s 219ms/step - loss: 0.1093 - acc: 0.9570 - val_loss: 0.5195 - val_acc: 0.8678\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 1742s 218ms/step - loss: 0.1002 - acc: 0.9610 - val_loss: 0.4533 - val_acc: 0.8719\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 1733s 217ms/step - loss: 0.0922 - acc: 0.9644 - val_loss: 0.4937 - val_acc: 0.8719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xfa92630>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This generator will fit the CNN on the training set and evaluate its performance in the test set\n",
    "#Without doing a optimization analysis of the code the accuracy from the training set is 0.9644 and test set 0.8719\n",
    "classifier.fit_generator(train_set,\n",
    "                            steps_per_epoch=8000,\n",
    "                            epochs=10,\n",
    "                            validation_data=test_set,\n",
    "                            validation_steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi image prediction using the CNN model\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import pandas as pd\n",
    "from pandas import DataFrame,Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Binary breakdown\n",
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_image=image.list_pictures('dataset/single_prediction/',ext='jpg')\n",
    "x=range(len(list_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=Series(x)\n",
    "prediction=Series(x)\n",
    "predictions=Series(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading images to the model\n",
    "#Converting the images into a 3D array\n",
    "for r in x:\n",
    "    test_image=image.load_img(path=list_image[r],target_size=(64,64))\n",
    "    test_image=image.img_to_array(test_image)\n",
    "    test_image=np.expand_dims(test_image,axis=0)\n",
    "    result[r]=classifier.predict(test_image)\n",
    "    if result[r]==1:\n",
    "        prediction='dog'\n",
    "        predictions[r]=np.array(prediction)\n",
    "    else:\n",
    "        prediction='cat'    \n",
    "        predictions[r]=np.array(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictive</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cat</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dog</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predictive Actual\n",
       "0         cat    cat\n",
       "1         cat    cat\n",
       "2         cat    cat\n",
       "3         cat    cat\n",
       "4         dog    dog\n",
       "5         cat    cat\n",
       "6         cat    cat\n",
       "7         dog    cat\n",
       "8         dog    dog\n",
       "9         dog    dog\n",
       "10        dog    dog\n",
       "11        dog    dog\n",
       "12        dog    dog"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Result of image predictions. #These images will be independent from both sets\n",
    "#The predictor correctly determined 12 of 13 images. That is a 92.3% accuracy. \n",
    "image_results=pd.DataFrame(['cat','cat','cat','cat','dog','cat','cat','cat','dog','dog','dog','dog','dog'],columns=['Actual'])\n",
    "predictions=pd.DataFrame(predictions,columns=['Predictive'])\n",
    "results=pd.concat([predictions,image_results],axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
